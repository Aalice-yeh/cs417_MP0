{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aalice-yeh/cs417_MP0/blob/main/SP26_CS410_lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U gensim"
      ],
      "metadata": {
        "id": "KXg3jq11Hsw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"presidential campaigns are complex\",\n",
        "    \"media reports on presidential campaigns\",\n",
        "    \"the cat eats fish\",\n",
        "    \"the dog eats meat\",\n",
        "    \"cats and dogs are domestic animals\",\n",
        "    \"dogs and wolves are related animals\",\n",
        "    \"computers process data\",\n",
        "    \"data science uses computers\",\n",
        "    \"machine learning analyzes data\",\n",
        "    \"artificial intelligence is related to machine learning\"\n",
        "]\n",
        "\n",
        "# Simple preprocessing\n",
        "processed_sentences = [s.lower().split() for s in sentences]\n",
        "\n",
        "print(processed_sentences[:2])"
      ],
      "metadata": {
        "id": "B1WrKWRoK3IA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "model = Word2Vec(\n",
        "    sentences=processed_sentences,\n",
        "    vector_size=50,   # size of word vectors\n",
        "    window=3,         # context window\n",
        "    min_count=1,      # keep all words\n",
        "    workers=1,\n",
        "    epochs=200        # more epochs since corpus is tiny\n",
        ")"
      ],
      "metadata": {
        "id": "zPPoo-fjHU99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Words similar to 'dog':\")\n",
        "print(model.wv.most_similar(\"dog\"))\n",
        "\n",
        "print(\"\\nWords similar to 'data':\")\n",
        "print(model.wv.most_similar(\"data\"))"
      ],
      "metadata": {
        "id": "m3sdyCWFHXnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.wv.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"])\n",
        "print(result)"
      ],
      "metadata": {
        "id": "hjvHG0vXHZtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.wv.most_similar(positive=[\"computers\", \"learning\"], negative=[\"data\"]))"
      ],
      "metadata": {
        "id": "HoFhXIFRHb-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Vector Comparison\n",
        "Cosine Similarity with `wv.similarity`"
      ],
      "metadata": {
        "id": "ixPKpLmF77uw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.wv.similarity(\"dog\", \"wolves\"))\n",
        "print(model.wv.similarity(\"dog\", \"computers\"))"
      ],
      "metadata": {
        "id": "VfG-J1IoHd1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Visualization of Word Vectors*"
      ],
      "metadata": {
        "id": "9tG-tymUHkr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "words = [\"presidential\",\"campaigns\",\"dog\", \"wolves\", \"cat\", \"computers\", \"data\", \"learning\"]\n",
        "vectors = [model.wv[w] for w in words]\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "coords = pca.fit_transform(vectors)\n",
        "\n",
        "for word, (x, y) in zip(words, coords):\n",
        "    plt.scatter(x, y)\n",
        "    plt.text(x+0.002, y+0.002, word)\n",
        "\n",
        "plt.title(\"Word Embeddings Visualized\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H-qHgjq2HkBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vector = model.wv['presidential']\n",
        "\n",
        "# Print the vector (a NumPy array)\n",
        "print(word_vector)\n",
        "# Print the shape of the vector\n",
        "print(word_vector.shape)"
      ],
      "metadata": {
        "id": "BeNZ-3EQhbf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write code to compute the dot-product similarity of the word \"presidential\" and the word \"computers\""
      ],
      "metadata": {
        "id": "_xEVfPtHiLRA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-SSX8hpOiJvr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}